{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Example Notebook\n",
    "\n",
    "This notebook demonstrates basic ML operations with numpy, torch, and transformers."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import BertConfig, BertModel\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the src directory to the Python path\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "# Import from our project\n",
    "from {{cookiecutter.project_slug}}.ml_example import numpy_calculations, torch_calculations, plot_data\n",
    "\n",
    "# Set up matplotlib for inline display\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Numpy Calculations\n",
    "\n",
    "Let's perform some basic calculations using numpy."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Run numpy calculations\n",
    "numpy_data = numpy_calculations()\n",
    "\n",
    "# Additional numpy operations\n",
    "# Create a random matrix with specific shape\n",
    "X = np.random.rand(100, 10)\n",
    "y = np.random.randint(0, 2, size=100)  # Binary classification for example\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Labels shape: {y.shape}\")\n",
    "\n",
    "# Show a sample\n",
    "print(f\"Sample features:{X[:5, :5]}\")\n",
    "print(f\"Sample labels: {y[:10]}\")\n",
    "\n",
    "# Class distribution\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "print(f\"Class distribution: {dict(zip(unique, counts))}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. PyTorch Calculations\n",
    "\n",
    "Now let's perform similar calculations using PyTorch."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Run torch calculations\n",
    "tensor, torch_output = torch_calculations()\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "print(f\"X tensor shape: {X_tensor.shape}\")\n",
    "print(f\"y tensor shape: {y_tensor.shape}\")\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "X_tensor = X_tensor.to(device)\n",
    "y_tensor = y_tensor.to(device)\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create a simple neural network\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(X.shape[1], 20),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(20, 2)\n",
    ").to(device)\n",
    "\n",
    "# Forward pass\n",
    "outputs = model(X_tensor)\n",
    "print(f\"Model output shape: {outputs.shape}\")\n",
    "print(f\"First few outputs:{outputs[:5]}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Visualization with Matplotlib\n",
    "\n",
    "Let's create some visualizations of our data."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Use the plot_data function from ml_example.py\n",
    "plot_data(numpy_data, outputs)\n",
    "\n",
    "# Create additional custom plots\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot 1: Heatmap of numpy matrix\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(X[:10, :10], cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.title('Feature Matrix Heatmap')\n",
    "\n",
    "# Plot 2: Line plot of numpy data\n",
    "plt.subplot(2, 2, 2)\n",
    "for i in range(5):  # First 5 features\n",
    "    plt.plot(X[:20, i], label=f'Feature {i+1}')  # First 20 samples\n",
    "plt.title('Feature Values')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "\n",
    "# Plot 3: Heatmap of model outputs\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(outputs[:10].detach().cpu().numpy(), cmap='plasma')\n",
    "plt.colorbar()\n",
    "plt.title('Model Outputs Heatmap')\n",
    "\n",
    "# Plot 4: Bar chart of class distribution\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.bar(unique, counts)\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Loading a Transformers Model from Custom Config\n",
    "\n",
    "Now let's create a small untrained BERT model from a custom configuration."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create a small transformer model with custom configuration\n",
    "config = BertConfig(\n",
    "    vocab_size=1000,          # Reduced vocabulary size\n",
    "    hidden_size=64,           # Smaller hidden size\n",
    "    num_hidden_layers=2,      # Fewer layers\n",
    "    num_attention_heads=2,    # Fewer attention heads\n",
    "    intermediate_size=256,    # Smaller intermediate size\n",
    "    max_position_embeddings=512\n",
    ")\n",
    "\n",
    "model = BertModel(config)\n",
    "\n",
    "# Print the configuration\n",
    "print(\"Custom BERT Configuration:\")\n",
    "print(config)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Print model summary\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# List some of the model's modules\n",
    "for name, module in list(model.named_modules())[:10]:  # Show only first 10 modules\n",
    "    print(f\"{name}: {module.__class__.__name__}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create a sample input\n",
    "batch_size = 2\n",
    "seq_length = 10\n",
    "input_ids = torch.randint(0, config.vocab_size, (batch_size, seq_length))\n",
    "attention_mask = torch.ones(batch_size, seq_length)\n",
    "\n",
    "print(f\"Input IDs shape: {input_ids.shape}\")\n",
    "print(f\"Attention mask shape: {attention_mask.shape}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Run the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "# Examine the outputs\n",
    "last_hidden_state = outputs.last_hidden_state\n",
    "pooler_output = outputs.pooler_output\n",
    "\n",
    "print(f\"Last hidden state shape: {last_hidden_state.shape}\")\n",
    "print(f\"Pooler output shape: {pooler_output.shape}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Visualize the embeddings\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot the last hidden state for the first sequence\n",
    "im = axes[0].imshow(last_hidden_state[0].detach().cpu().numpy(), cmap='viridis')\n",
    "plt.colorbar(im, ax=axes[0])\n",
    "axes[0].set_title('Last Hidden State (First Sequence)')\n",
    "axes[0].set_xlabel('Hidden Dimension')\n",
    "axes[0].set_ylabel('Sequence Position')\n",
    "\n",
    "# Plot the pooler output\n",
    "axes[1].bar(range(pooler_output[0].shape[0]), pooler_output[0].detach().cpu().numpy())\n",
    "axes[1].set_title('Pooler Output (First Sequence)')\n",
    "axes[1].set_xlabel('Hidden Dimension')\n",
    "axes[1].set_ylabel('Value')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated:\n",
    "\n",
    "1. Basic calculations with NumPy\n",
    "2. Similar operations with PyTorch\n",
    "3. Data visualization with Matplotlib\n",
    "4. Creating and using a small untrained transformer model from a custom configuration\n",
    "\n",
    "These examples show how to use the core libraries included in this ML project template.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
